第 4 课：
微调简介：
一个好的框架是有一个基础数据集，然后是一个指令数据集。 需要调整指令以使模型以所需的格式回答所提出的问题
XTuner简介：
InternLM 使用的格式与 LLaMA 略有不同。 对于模型的预训练，会根据其完成文本的方式进行评估，而对于指令调整，它通常会采取不同的方式。 有时使用 LoRA 可以降低计算强度并使用更少的内存。 LoRA 很好，而 QLoRA 更好，并且在 VRam 耗尽的情况下也能够使用 CPU 内存。
XTuner 兼容：
XTuner 与所有主要型号提供商和 Nvidia GPU 兼容。 Xtuner 提供了一个统一的界面来下载不同精度的模型，无论是否带有适配器。 XTuner 还附带了一种有用的数据格式。
如果我没有内存(8Gb)怎么办
您还可以添加闪光关注。
InternLM Studio 使用方法：
使用 SSH 或其他方法进入您的环境。 要设置 SSH，您需要公钥。 输入 bash 然后开始。 然后，您将运行各种程序来安装依赖项。 确保创建新目录以保持井井有条，不会造成混乱。 之后下载数据集或使用内置数据集。 不同型号有多种预制配置模式。 您可以通过直接编辑模式配置模型来更改各种内容，具体的超级参数在 GitHub 文档中。 在微调之前，它将初始化数据集，然后对数据集进行标记。 它以特定的方式加载它。
加速度：
深速零2。 等待之后，您会看到损失变得平坦并收敛。 Deepspeed 非常复杂。
多路复用器：
这家伙喜欢 Tmux。 出于充分的理由，我们可以在离开时将其保留。 Tmux 还意味着您可以运行其他东西。
连接超时。 他进入自己的环境并希望能够记住。 我的人犯了一个错误，试图运行该文件很长时间，但没时间了。 我有点为他感到难过。 然而，它确实保存了训练期间保存的检查点。
也许这是有目的的教如何将 pth 转换为 Huggingface 格式。 还有合并模型的功能。 之后我们就可以进行对话。 您还可以使用量化来使其更快。
有趣的参数：
种子、top-p、温度。 我们还可以尝试其他数据集。 对于此示例，我们使用 MedQA。
数据集准备：
首先你必须对数据集进行排序，所有数据都在 Excel 电子表格中，这并不容易。 其他程序用于将 Excel 电子表格转换为 jsonl，这是正确的框架。 移动一些文件，编辑它们，最后你可以用它来训练。 这家伙很酷，因为他不喜欢 VIM，非常尊重。 要使其正常工作，您必须直接编辑适用的参数。
代理商：
MSAgent 是一个受支持的框架。 您可以使用它向谷歌输入查询。 Lagent 也可以运行。 这是一个很好的教训。
