第 3 课：
一般介绍：
我们将使用各种工具来提示工程师LLM并让它完成各种任务。
AI模型的局限性：
无法接受当前语言，这意味着数据截止日期之后发生的事件将不为人所知或可能被最坏地猜测。
RAG 与 Finetune
RAG 是一种搜索形式并提供数据，它取决于人工智能已经知道如何完成任务并且只需要数据的假设。 微调更全面，但也需要付出更多的努力才能做好。 本节课的重点是 RAG。
抹布：
使用 Langchain 将知识传递给 InternLM。 Langchain 是一个有助于创建 RAG 管道（或他们所说的链）的程序。 它使用逻辑框架来计划和转移数据，以获得 InternLM 所需的知识。
大样本的问题：
创建大量字符长度相同的样本。
管道的起点是查询，然后从查询中推断出 AI 模型所需的数据。 按主题对大量文本进行排序是理想的选择。
演示；
使用渐变。
实习生LM用法：
像往常一样设置环境并为模型文件创建一个新目录。 为数据创建另一个文件夹。 然后我们使用 python 在 Huggingface 中运行命令来下载另一个模型。 然后我们运行新代码。 该模型用于对数据库进行排序。 创建一个新的演示存储库并使用 python 程序创建矢量数据库。 仅使用 txt 和 md 文件。 我们定义要读入的文件夹并列出它们。 然后我们还需要嵌入迄今为止使用过的所有数据。 Chroma 是使用的数据库。 您只需运行该程序一次。
InternLM 第 2 部分的用法：
创建 InternLM 实例并使用聊天界面。 这将在第一部分之后运行。 然后我们创建一个脚本，使用 Langchain 将所有其他程序组合在一起。 它还包括一个列出了所需行为的模板。
网络演示：
在终端中输入 web_demo.put 并在 Web 浏览器中加载提供的 IP。
